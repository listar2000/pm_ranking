src.pm_rank.data
================

.. py:module:: src.pm_rank.data

.. autoapi-nested-parse::

   Data subpackage for pm_rank.



Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/src/pm_rank/data/base/index
   /autoapi/src/pm_rank/data/loaders/index
   /autoapi/src/pm_rank/data/utils/index


Classes
-------

.. autoapisummary::

   src.pm_rank.data.ForecastEvent
   src.pm_rank.data.ForecastProblem
   src.pm_rank.data.ForecastChallenge
   src.pm_rank.data.ChallengeLoader
   src.pm_rank.data.GJOChallengeLoader


Package Contents
----------------

.. py:class:: ForecastEvent

   Bases: :py:obj:`pydantic.BaseModel`


   Individual forecast from a user for a specific problem.


   .. py:attribute:: problem_id
      :type:  int


   .. py:attribute:: username
      :type:  str


   .. py:attribute:: timestamp
      :type:  datetime.datetime


   .. py:attribute:: probs
      :type:  List[float]


   .. py:attribute:: correct_prob
      :type:  float


   .. py:method:: validate_probabilities(v)

      Validate that probabilities sum to 1 and are non-negative.



   .. py:method:: validate_correct_probability(v, info)

      Validate that correct_prob matches one of the probabilities.



.. py:class:: ForecastProblem

   Bases: :py:obj:`pydantic.BaseModel`


   A prediction problem with multiple options and forecasts.


   .. py:attribute:: title
      :type:  str


   .. py:attribute:: problem_id
      :type:  int


   .. py:attribute:: options
      :type:  List[str]


   .. py:attribute:: correct_option
      :type:  str


   .. py:attribute:: forecasts
      :type:  List[ForecastEvent]


   .. py:attribute:: end_date
      :type:  datetime.datetime


   .. py:attribute:: num_forecasters
      :type:  int


   .. py:attribute:: url
      :type:  str | None


   .. py:attribute:: odds
      :type:  List[float] | None


   .. py:method:: validate_correct_option(v, info)

      Validate that correct_option is in the options list.



   .. py:method:: validate_forecasts(v, info)

      Validate that all forecasts have correct number of probabilities.



   .. py:method:: validate_odds(v, info)

      Validate that odds match the number of options if provided.



   .. py:property:: has_odds
      :type: bool


      Check if the problem has odds data.



   .. py:property:: crowd_probs
      :type: List[float]


      Calculate crowd probabilities from the forecasts.



   .. py:property:: unique_forecasters
      :type: List[str]


      Get list of unique forecasters for this problem.



.. py:class:: ForecastChallenge

   Bases: :py:obj:`pydantic.BaseModel`


   A collection of forecast problems with validation and computed properties.


   .. py:attribute:: title
      :type:  str


   .. py:attribute:: forecast_problems
      :type:  List[ForecastProblem]


   .. py:method:: validate_problems(v)

      Validate that there are problems and they have unique IDs.



   .. py:property:: forecaster_map
      :type: Dict[str, List[ForecastEvent]]


      Map from forecaster username to their forecasts across all problems.



   .. py:property:: num_forecasters
      :type: int


      Total number of unique forecasters across all problems.



   .. py:property:: unique_forecasters
      :type: List[str]


      List of unique forecaster usernames.



   .. py:method:: get_forecaster_problems(username: str) -> List[ForecastProblem]

      Get all problems that a specific forecaster participated in.



   .. py:method:: get_problem_by_id(problem_id: int) -> ForecastProblem | None

      Get a specific problem by its ID.



   .. py:method:: get_problems(nums: int = -1) -> List[ForecastProblem]

      Get a list of problems. If nums is -1, return all problems.



   .. py:method:: stream_problems(order: Literal['sequential', 'random', 'time'] = 'sequential', increment: int = 100) -> Iterator[List[ForecastProblem]]

      Stream the problems in the challenge. Either by random or by the problem end time.

      Args:
          order: The order in which to stream the problems.
          increment: The number of problems to stream in each iteration.

      Returns:
          An iterator of lists of problems.



   .. py:method:: stream_problems_over_time(increment_by: Literal['day', 'week', 'month'] = 'day', min_bucket_size: int = 1) -> Iterator[Tuple[str, List[ForecastProblem]]]

      Stream all problems in chronological buckets.

      Each bucket covers a contiguous time window of length *increment_by* (day, week, or
      month).  If the window does **not** yet contain *min_bucket_size* problems, the
      window is repeatedly extended by another *increment_by* until the size
      requirement is met **or** no problems remain.  All problems whose ``end_date`` is
      **strictly after** the previous bucket boundary *and* **≤** the current bucket
      boundary are included.

      The timestamp returned for a bucket is the *inclusive* upper‐bound boundary
      expressed in ISO‑8601 (YYYY‑MM‑DD).

      Args:
          increment_by: The time interval to stream problems in a bucket.
          min_bucket_size: The minimum number of problems to stream in each bucket.

      Returns:
          An iterator where each element is a bucket of (timestamp, list of problems).



   .. py:method:: fill_problem_with_fair_odds(force: bool = False) -> None

      Certain challenge do not have odds data, we can fill in fair/uniform odds for each problem.
      If `force` is True, we will not check whether the problem already has odds data.



.. py:class:: ChallengeLoader

   Bases: :py:obj:`abc.ABC`


   Abstract base class for loading forecast challenges from different data sources.
   This separates the loading logic from the data model.


   .. py:method:: load_challenge() -> ForecastChallenge
      :abstractmethod:


      Load and return a ForecastChallenge from the data source.



   .. py:method:: get_challenge_metadata() -> Dict[str, Any]
      :abstractmethod:


      Get metadata about the challenge without loading all data.



.. py:class:: GJOChallengeLoader(predictions_df: Optional[pandas.DataFrame] = None, predictions_file: Optional[str] = None, metadata_file: Optional[str] = None, challenge_title: str = '')

   Bases: :py:obj:`src.pm_rank.data.base.ChallengeLoader`


   Load forecast challenges from GJO (Good Judgment Open) data format.

   Initialize the GJOChallengeLoader. The challenge can be either loaded with a given `pd.DataFrame` or with             a combination of paths `predictions_file` and `metadata_file`.

   Args:
       predictions_df (pd.DataFrame): a pd.DataFrame containing the predictions. If provided,                 `predictions_file` and `metadata_file` will be ignored.
       predictions_file (str): the path to the predictions file
       metadata_file (str): the path to the metadata file
       challenge_title (str): the title of the challenge


   .. py:attribute:: challenge_title
      :value: ''



   .. py:attribute:: logger


   .. py:method:: load_challenge(forecaster_filter: int = 0, problem_filter: int = 0) -> src.pm_rank.data.base.ForecastChallenge

      Load challenge data from GJO format files.

      Args:
          forecaster_filter: minimum number of events for a forecaster to be included
          problem_filter: minimum number of events for a problem to be included

      Returns:
          ForecastChallenge: a ForecastChallenge object containing the forecast problems and events



   .. py:method:: get_challenge_metadata() -> Dict[str, Any]

      Get basic metadata about the GJO challenge.



