<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>How We Score &amp; Rank LLMs in Prophet Arena | PM-RANK 0.2.20 documentation</title>
<meta content="How We Score &amp; Rank LLMs in Prophet Arena | PM-RANK 0.2.20 documentation" property="og:title"/>
<meta content="How We Score &amp; Rank LLMs in Prophet Arena | PM-RANK 0.2.20 documentation" name="twitter:title"/>
<link href="../_static/pygments.css?v=e72c8e07" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=42baaae4" rel="stylesheet" type="text/css"/>
<link href="../_static/graphviz.css?v=4ae1632d" rel="stylesheet" type="text/css"/>
<link href="../_static/custom.css?v=4cdea68d" rel="stylesheet" type="text/css"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../autoapi/src/pm_rank/model/utils/index.html" rel="prev" title="src.pm_rank.model.utils"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">PM-RANK 0.2.20 documentation</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">‚åò</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/listar2000/pm_ranking" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg style="height: 1.75em; width: 1.75em; vertical-align: -0.125em;" viewbox="0 0 496 512">
<path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70.7 1.4-85.9-35.4 0 0-11.4-29.7-27.8-37.4 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" fill="currentColor"></path>
</svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" aria-label="Color theme switcher" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../index.html"><span class="font-bold text-clip whitespace-nowrap">PM-RANK 0.2.20 documentation</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Links:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../colab_demo.html">Colab Demo</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../autoapi/src/pm_rank/index.html">src.pm_rank<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../autoapi/src/pm_rank/data/index.html">src.pm_rank.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/src/pm_rank/model/index.html">src.pm_rank.model</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Blogposts:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">How We Score &amp; Rank LLMs in Prophet Arena</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">PM-RANK 0.2.20 documentation</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div>
<span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">
    How We Score &amp; Rank LLMs in Prophet Arena
  </span>
</nav>
<div id="content" role="main">
<section id="how-we-score-rank-llms-in-prophet-arena">
<h1>How We Score &amp; Rank LLMs in Prophet Arena<a class="headerlink" href="#how-we-score-rank-llms-in-prophet-arena" title="Link to this heading"><span>¬∂</span></a></h1>
<blockquote>
<div><p><strong>Author:</strong> Sida Li, Prophet Arena Team</p>
<p><strong>Date:</strong> August 10, 2025</p>
<p><strong>Estimated Reading Time:</strong> 10 minutes</p>
</div></blockquote>
<hr class="docutils"/>
<p>Creating benchmarks and arenas to evaluate large language models (LLMs) is often a labor-intensive and meticulous process. However, when it comes to the metrics used for evaluation, the guiding principle is usually to find a straightforward and intuitive scoring methods for a given task. For example, in problems involving pairwise comparisons (‚ÄúWhich LLM answers better?‚Äù), the <a class="reference external" href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating system</a> offers a clean and elegant solution. Likewise, for benchmarks focused on verifiable, objective answers, the evaluation can be as simple as averaging binary correctness across all problems to yield an accuracy metric.</p>
<p>However, the question of <strong>how to score and rank LLMs based on their probabilistic predictions</strong> introduces more complexity and nuance. Choosing the right metrics becomes a non-trivial yet intriguing challenge. One distinctive strength of our platform, <code class="docutils literal notranslate"><span class="pre">ProphetArena</span></code>, lies precisely in our comprehensive scoring and ranking module. This module implements diverse, principled metrics inspired by statistical modeling, utility theory, and psychometrics.</p>
<p>In this post, we‚Äôll guide you through the reasoning behind our metric choices and describe how these metrics help us robustly evaluate LLM performance in prediction-market scenarios.</p>
<section id="tl-dr-for-readers-in-a-hurry">
<h2>TL;DR (for readers in a hurry)<a class="headerlink" href="#tl-dr-for-readers-in-a-hurry" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#tl-dr-for-readers-in-a-hurry'"><span>¬∂</span></a></h2>
<ul>
<li><p>Our default scoring metric in <code class="docutils literal notranslate"><span class="pre">ProphetArena</span></code> is the <strong>Brier score</strong>‚Äîa well-established <a class="reference external" href="https://en.wikipedia.org/wiki/Scoring_rule">proper scoring rule</a>. The Brier score captures the core question:</p>
<blockquote>
<div><p><em>‚ÄúHow well does the predicted probability distribution match reality (the observed outcome)?‚Äù</em></p>
</div></blockquote>
<p>It naturally generalizes beyond binary outcomes, assessing both accuracy and calibration.</p>
</li>
<li><p>We‚Äôve innovatively introduced a class of <strong>averaged return metrics</strong> as complementary indicators. Intuitively, these metrics simulate the long-term returns of someone consistently betting based purely on the LLM‚Äôs probability estimates, using the same budget for each event.</p></li>
<li><p>We incorporate additional metrics such as an <strong>IRT (Item Response Theory) score</strong>, which jointly models each LLM‚Äôs predictive ability alongside event-specific difficulty and discrimination parameters, and a <strong>generalized Bradley‚ÄìTerry model</strong>, a rating system akin to Elo ratings, providing intuitive comparative scores.</p></li>
<li><p>All these metrics are efficiently implemented and packaged into our standalone Python package <a class="reference external" href="https://pypi.org/project/pm-rank/"><code class="docutils literal notranslate"><span class="pre">pm_rank</span></code></a>, fully documented and open-sourced to facilitate better evaluation of LLMs in general prediction-market environments.</p></li>
</ul>

<p align="center">
<img alt="pm_rank package" src="../_static/rank_overview.png" width="600"/>
</p>
</section>
<section id="scoring-rules-grounded-metric-for-probabilistic-predictions">
<h2>Scoring Rules: grounded metric for probabilistic predictions<a class="headerlink" href="#scoring-rules-grounded-metric-for-probabilistic-predictions" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#scoring-rules-grounded-metric-for-probabilistic-predictions'"><span>¬∂</span></a></h2>
<p><strong>We begin with some setup:</strong> we want to score the LLM‚Äôs probabilistic predictions for multiple events <span class="math notranslate nohighlight">\(E_1,...,E_N\)</span>. In each event <span class="math notranslate nohighlight">\(i\)</span>, there are <span class="math notranslate nohighlight">\(n_i\)</span> mutually exclusive potential outcomes (e.g. <span class="math notranslate nohighlight">\(n_i = 30\)</span> for the event <em>‚ÄúNBA champion in 2026‚Äù</em>). The LLM prediction is then represented as a probability vector <span class="math notranslate nohighlight">\((p_{i1}, p_{i2}, \dots, p_{in_i})\)</span>, summing to 1. Once the event outcome is realized‚Äîsay, outcome <span class="math notranslate nohighlight">\(j\)</span>‚Äîwe calculate the prediction accuracy using scoring rules, specifically for the Brier score:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
BS_i \equiv \text{Brier Score for } E_i = \frac{1}{n_i} \sum_{k=1}^{n_i}(p_{ik} - o_{ik})^2
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(o_{ik}\)</span> is 1 if outcome <span class="math notranslate nohighlight">\(k\)</span> occurred, and 0 otherwise. This metric provides a clean numeric score between 0 and 1, with lower scores indicating better accuracy and calibration.</p>
<blockquote>
<div><p>üîç <strong>Remark for careful readers</strong></p>
<p>In the setup above (and the rest of the post), we considered a <strong>simplified setting</strong> where all the potential outcomes (or <code class="docutils literal notranslate"><span class="pre">markets</span></code>) in an event are <em>mutually exclusive</em>. While this assumption holds naturally in certain cases (e.g. sports betting on which team will win the championship), it can be seriously violated in other cases (e.g. the markets ‚ÄúBitcoin price will be above 100k dollars‚Äù and ‚ÄúBitcoin price will be above 101k dollars‚Äù are actually highly correlated). Fortunately, even in the general case, the Brier score can generalize easily, but other metrics mentioned below might require extra approximation or adaptation. We will detail the generalized version of our scoring/ranking methods in the upcoming paper.</p>
</div></blockquote>
<p>The final (averaged) Brier score is then calculated across all events:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
BS = \frac{1}{N} \sum_{i=1}^{N} BS_i
\end{equation*}\]</div>
<p>and used as the score to rank the LLMs (the smaller the better).</p>
<p>Unlike simple accuracy measures, scoring rules like the Brier score provide richer information, particularly useful when dealing with multiple outcomes (<span class="math notranslate nohighlight">\(n_i &gt; 2\)</span>). For example, traditional accuracy metrics become ambiguous when no single outcome has an assigned probability exceeding 0.5‚Äîshould we pick the highest-probability option, or refuse to make a deterministic guess? Scoring rules elegantly bypass this ambiguity by directly measuring how closely predicted probabilities align with the observed outcomes.</p>
<p>Furthermore, proper scoring rules inherently reward models that are both accurate and well-calibrated. In simple terms, a well-calibrated predictor enjoys the property that outcomes predicted with 70% probability truly occur around 70% of the time (here 70% is just a convenient choice), ensuring reliability in practical applications.</p>
<p>It‚Äôs worth noting that popular real-world forecasting platforms, such as <a class="reference external" href="https://www.gjopen.com/">Good Judgment Open</a>, also widely adopt variations of the Brier score, showing its long-established practicality in prediction markets. Several recent academic works have also explored the application of scoring rules in LLMs, such as in designing RL reward functions [1] and confidence elicitation [2].</p>
<p>While the Brier score serves as our default scoring method due to its interpretability and robustness, we also make other proper scoring rules, such as the logarithmic (log) and spherical scores, availabe in the <code class="docutils literal notranslate"><span class="pre">pm_rank</span></code> package. The intuitive interpretation of the Brier score makes it our primary evaluation metric.</p>
</section>
<section id="averaged-return-what-practitioners-might-care-about">
<h2>Averaged Return: what practitioners might care about<a class="headerlink" href="#averaged-return-what-practitioners-might-care-about" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#averaged-return-what-practitioners-might-care-about'"><span>¬∂</span></a></h2>
<p>In real-world prediction markets, practitioners care deeply about <strong>actionable insights</strong>‚Äîspecifically, how much money one could earn by faithfully following an LLM‚Äôs probabilistic predictions. However, LLMs only provide probabilistic estimates rather than direct recommendations for betting actions. Turning these estimates into concrete actions typically involves comparing the LLM‚Äôs belief (probability) against market-implied probabilities.</p>
<blockquote>
<div><p>üîç <strong>Remark for careful readers</strong></p>
<p>Here we once again introduce the metric under our <strong>simplified setting</strong> where all the potential outcomes (or <code class="docutils literal notranslate"><span class="pre">markets</span></code>) in an event are <em>mutually exclusive</em>. To understand the details and math formulations behind the generic algorithm, which is what we implement in the <code class="docutils literal notranslate"><span class="pre">pm_rank</span></code> package, please refer to the <a class="reference internal" href="#../_static/technical_doc.pdf"><span class="xref myst">our technical document</span></a>.</p>
</div></blockquote>
<p>To address this, we‚Äôve introduced a novel approach rooted in <strong>constant-relative-risk-aversion (CRRA) utility theory</strong>. Specifically, we assume a hypothetical scenario where a human fully trusts the LLM‚Äôs probabilities as their true beliefs and makes decisions guided solely by their personal risk aversion, captured by the CRRA utility function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
U_\gamma(w)=
\begin{cases}
\dfrac{w^{1-\gamma}}{\,1-\gamma\,}, &amp; 0\le\gamma&lt;1, \\
\log w, &amp; \gamma=1
\end{cases}
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma \in [0, 1]\)</span> is a risk-aversion hyperparameter, and <span class="math notranslate nohighlight">\(w\)</span> is the amount of money earned after making the bet. A <span class="math notranslate nohighlight">\(\gamma = 0\)</span> characterizes a risk-neutral individual, while <span class="math notranslate nohighlight">\(\gamma = 1\)</span> represents a logarithmic risk-averse profile. Intermediate values of <span class="math notranslate nohighlight">\(\gamma\)</span> represent varying degrees of risk aversion.</p>
<p align="center">
<img alt="CRRA Utility Function" src="../_static/crra_utility_plot.png" title="CRRA Utility Function" width="700"/>
</p>
<p>Other than the utility function, two other factors would influence the <strong>optimal betting strategy</strong>:</p>
<ol class="arabic simple">
<li><p><strong>How much money (total budget) to bet:</strong> for simplicity, we assume in our hypothetical scenarior that the bettor has a fixed budget of <strong>one dollar</strong> for each event, so the total budget is <span class="math notranslate nohighlight">\(N\)</span>. In other words, for the <span class="math notranslate nohighlight">\(i\)</span>-th event, any <strong>action/strategy</strong> can be represented as a vector <span class="math notranslate nohighlight">\(a_i = (a_{i1}, a_{i2}, \dots, a_{in_i})\)</span> that sums to 1, where <span class="math notranslate nohighlight">\(a_{ik}\)</span> is the amount bet on outcome <span class="math notranslate nohighlight">\(k\)</span> of event <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p><strong>The market odds/implied probabilities:</strong> these are the probabilities derived from the (human) market prices of the outcomes, which we denote as <span class="math notranslate nohighlight">\(q_{ik}\)</span> for outcome <span class="math notranslate nohighlight">\(k\)</span> of event <span class="math notranslate nohighlight">\(i\)</span>. In simple terms, <span class="math notranslate nohighlight">\(q_{ik}\)</span> is the market-consensus price of an ‚Äúall-or-nothing‚Äù contract, which pays one dollar if outcome <span class="math notranslate nohighlight">\(k\)</span> occurs and zero otherwise. In practice, we retrieve this information from human prediction markets, such as <a class="reference external" href="https://kalshi.com/">Kalshi</a>.</p></li>
</ol>
<p>Once these factors are determined, we can determine the optimal strategy <span class="math notranslate nohighlight">\(a_i^*\)</span> for event <span class="math notranslate nohighlight">\(E_i\)</span> by solving an optimization problem. The <em>optimality</em> is defined in terms of maximizing the expected utility of the bettor, given their risk aversion <span class="math notranslate nohighlight">\(\gamma\)</span> and using LLM‚Äôs predicted probabilities <span class="math notranslate nohighlight">\(p_{ik}\)</span> as the true beliefs. While the detailed derivation is beyond the scope of this post, the solution can be expressed in closed and interpretable forms depending on the risk aversion <span class="math notranslate nohighlight">\(\gamma\)</span>:</p>
<ul class="simple">
<li><p><strong>Risk-neutral (linear utility)</strong> individuals (<span class="math notranslate nohighlight">\(\gamma=0\)</span>) bet entirely on the option with the greatest discrepancy (<span class="math notranslate nohighlight">\(k^* := \max_k \frac{p_{ik}}{q_{ik}}\)</span>, sometimes denoted as <strong>edge</strong>) between LLM probabilities and market odds.</p></li>
<li><p><strong>Logarithmic utility (<span class="math notranslate nohighlight">\(\gamma=1\)</span>)</strong> bettors allocate their budget proportionally according to the LLM‚Äôs probabilities, i.e. <span class="math notranslate nohighlight">\(a_{ik}^* \propto p_{ik}\)</span>.</p></li>
<li><p><strong>Intermediate risk aversions (<span class="math notranslate nohighlight">\(0 &lt; \gamma &lt; 1\)</span>)</strong> smoothly interpolate between these two extremes, providing flexible yet clearly interpretable betting strategies.</p></li>
</ul>
<p>Our averaged return metric then measures the long-term rate of return by following the optimal betting strategy <span class="math notranslate nohighlight">\(a_i^*\)</span> across all events. Specifically, we define the <strong>averaged return score (AVER)</strong> as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
AVER := \frac{\sum_{i=1}^{N} \text{payoff from } i\text{-th } \text{event under } a_i^*}{N}.
\end{equation*}\]</div>
<p>where the payoff is simply <span class="math notranslate nohighlight">\(a_{ik}^*\)</span> whenever outcome <span class="math notranslate nohighlight">\(k\)</span> occurs. We need to specify the hyperparameter <span class="math notranslate nohighlight">\(\gamma\)</span> to compute the AVER. By default, we follow the risk-neutral case (<span class="math notranslate nohighlight">\(\gamma=0\)</span>), but our platform also allows users to vary this factor (perhaps based on their own risk preferences). Below we show three moving AVER metrics over time (as more and more prediction events are closed) for four LLMs and <span class="math notranslate nohighlight">\(\gamma = 0, 0.5, 1\)</span>:</p>
<p align="center">
<img alt="Averaged Return Score" src="../_static/prophet_arena_risk_curves_0717.png" title="Averaged return curves for LLMs, generated with `pm_rank`." width="800"/>
<p>Creating such plots is straightforward and efficient using the built-in functions in the <code class="docutils literal notranslate"><span class="pre">pm_rank</span></code> package.</p>
</p>
<section id="absolute-versus-relative-metrics">
<h3>üí≠ Absolute versus relative metrics<a class="headerlink" href="#absolute-versus-relative-metrics" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#absolute-versus-relative-metrics'"><span>¬∂</span></a></h3>
<p>It is now the right time to reflect and compare the two important metrics introduced so far. Despite the obvious differences in their mathematical formulations, a more high-level distinction to keep in mind is that: the Brier score is an <strong>absolute metric</strong>, while the averaged return score is a <strong>relative metric</strong>. To elaborate:</p>
<ul class="simple">
<li><p>When we calculate the Brier score (or any other proper scoring rule), we measure how the LLM‚Äôs probabilistic predictions align with the observed outcomes. A good score means that the LLM can effectively synthesize the provided information and make accurate &amp; well-calibrated predictions through reasoning. The market odds, which can be interpreted as the human-consensus probabilities, <strong>do not enter into the calculation</strong>.</p></li>
<li><p>On the other hand, the averaged return depends on the observed outcome and the strategy <span class="math notranslate nohighlight">\(a_i^*\)</span>, which in turn is determined by <strong>both the LLM‚Äôs probabilities and the market odds</strong>. It is thus a <strong>relative metric</strong> in the sense that achieving a good score requires the LLM to perform ‚Äúrelatively better‚Äù than most human bettors to create arbitrage opportunities.</p></li>
</ul>
</section>
<section id="example-when-would-absolute-and-relative-metrics-differ">
<h3>ü§î Example: When Would Absolute and Relative Metrics Differ?<a class="headerlink" href="#example-when-would-absolute-and-relative-metrics-differ" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#example-when-would-absolute-and-relative-metrics-differ'"><span>¬∂</span></a></h3>
<p>Suppose we bet on a single event with binary outcomes, with ground-truth probability of ‚ÄúYes‚Äù being 0.6 (for the event to be realized), and prediction market price 0.5. Consider two different probabilistic predictions of this event‚Äôs ‚ÄúYes‚Äù realization: A predicts 0.45 and B predicts 0.9.</p>
<p>The expected Brier Score of A is</p>
<p>$$
1 - 0.6 \cdot (0.45‚àí1)^2 + 0.4 \cdot (0.45‚àí0)^2 = 1 - 0.2625 = 0.7375
$$</p>
<p>The expected Brier Score of B is</p>
<p>$$
1 - 0.6 \cdot (0.9 - 1)^2 + 0.4 \cdot (0.9‚àí0)^2 = 1 - 0.33 = 0.67
$$</p>
<p>So A has a higher Brier Score. However, because A predicts 0.45, lower than the 0.5 prediction market price, hence A will short ‚ÄúYes‚Äù (or equivalently, buy ‚ÄúNo‚Äù) at 0.5. Meanwhile, B predicts 0.9, much higher than the prediction market price, hence they will buy ‚ÄúYes.‚Äù Respectively, A and B‚Äôs expected return will be</p>
<p>$$</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
0.6 \cdot (‚àí1+0.5) + 0.4 \cdot (0.5) &amp;= ‚àí0.1 \\
0.6 \cdot (1‚àí0.5) + 0.4 \cdot (‚àí0.5) &amp;= 0.1
\end{align*}\]</div>
<p>$$</p>
<p>In this example, A has a higher Brier Score, but lower returns.</p>
<p>This example uncovers a key difference between the above two metrics. The Brier Score measures how close a prediction is to the ground truth and, importantly, has nothing to do with the market prices. Since A‚Äôs prediction above is closer to the ground truth, it receives a higher Brier Score. However, returns on the market are not only driven by the true probability but also the market price. Therefore, even though B‚Äôs prediction is exaggerated, it lies on the correct side of the market mispricing (buys ‚ÄúYes‚Äù when outcome is more likely than price suggests), achieving higher returns.</p>
</section>
</section>
<section id="irt-bradley-terry-lens-of-statistical-modeling">
<h2>IRT &amp; Bradley-Terry: lens of statistical modeling<a class="headerlink" href="#irt-bradley-terry-lens-of-statistical-modeling" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#irt-bradley-terry-lens-of-statistical-modeling'"><span>¬∂</span></a></h2>
<p>In addition to the previously mentioned metrics, we also incorporate statistically-grounded methods such as <strong>Item Response Theory (IRT)</strong> and the <strong>Bradley‚ÄìTerry (BT) model</strong> to gain deeper insights into LLM performance. Unlike simpler metrics, these methods rely on fitting statistical models to data‚Äîthus they tend to require larger datasets and careful model fitting procedures.</p>
<section id="item-response-theory-irt">
<h3>Item Response Theory (IRT)<a class="headerlink" href="#item-response-theory-irt" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#item-response-theory-irt'"><span>¬∂</span></a></h3>
<p>IRT addresses a critical limitation in simpler scoring methods: equal weighting of all prediction events. Using a slight variant [3] of the <a class="reference external" href="https://assess.com/what-is-the-two-parameter-irt-2pl-model/">two-parameter logistic (2-PL) IRT model</a>, we jointly estimate each LLM‚Äôs capability parameter alongside the <strong>difficulty and discrimination parameters</strong> for each prediction event. Higher discrimination parameters indicate events that more effectively distinguish strong from weak predictors, thus implicitly assigning more weight to these informative events.</p>
<p>This approach is highly versatile. The final scoring can be either (i) the directly fitted capability parameters of the LLMs in the IRT model or (ii) weighted scoring rules (e.g. Brier score) using event-level discrimination parameters. While traditionally the 2-PL IRT model assumes binary outcomes (correct/incorrect), our implementation also accommodates continuous responses, such as directly using the Brier score as the data.</p>
<p>Initial empirical results suggest that: even though IRT model fitting requires scaling up both the number of prediction events and the number of LLMs, it provides a robust and principled evaluation framework (in the sense that the two implementations (i) and (ii) above achieve high correlation). Once we obtan sufficient data, it is expected that <strong>we might migrate our default scoring metric from the current (unweighted) Brier score to the IRT-based weighted version</strong>, and we will likely publish a separate follow-up post detailing our practice.</p>
</section>
<section id="generalized-bradleyterry-bt-model">
<h3>Generalized Bradley‚ÄìTerry (BT) Model<a class="headerlink" href="#generalized-bradleyterry-bt-model" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#generalized-bradleyterry-bt-model'"><span>¬∂</span></a></h3>
<p>The generalized BT model [4] extends traditional pairwise-comparison methods‚Äîlike those used by <a class="reference external" href="https://lmarena.ai/">LMArena</a>‚Äîto our prediction-market setting. Here, each event outcome is viewed as a contest between two ‚Äúpseudo-teams‚Äù: a winning team <span class="math notranslate nohighlight">\(w_i\)</span> (corresponding to the realized outcome) and a losing team <span class="math notranslate nohighlight">\(l_i\)</span>. Each participating LLM contributes fractions of its capability proportional to its predicted probabilities, allocating <span class="math notranslate nohighlight">\(p_{ik}\)</span> to the winning team and <span class="math notranslate nohighlight">\(1 - p_{ik}\)</span> to the losing team.</p>
<p>We model the winning probability for <span class="math notranslate nohighlight">\(E_i\)</span> using the BT formulation:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\frac{e^{\theta_{w_i}}}{e^{\theta_{w_i}} + e^{\theta_{l_i}}}
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_{w_i}\)</span> and <span class="math notranslate nohighlight">\(\theta_{l_i}\)</span> are the summed <em>‚Äúfractional‚Äù</em> capabilities of the winning and losing teams, respectively. Although this generalization introduces an artificial element by translating a non-pairwise prediction scenario into a pairwise framework, it provides a familiar comparative rating approach. Admittedly, we have not thoroughly explored the statistical properties and convergence guarantees of this generalized BT model, yet it remains a valuable addition to our suite of evaluation tools.</p>
</section>
<hr class="docutils"/>
<section id="references">
<h3>References:<a class="headerlink" href="#references" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#references'"><span>¬∂</span></a></h3>
<p>[1] Damani, Mehul, et al. ‚ÄúBeyond Binary Rewards: Training LMs to Reason About Their Uncertainty.‚Äù arXiv preprint arXiv:2507.16806 (2025).</p>
<p>[2] Xu, Tianyang, et al. ‚ÄúSayself: Teaching llms to express confidence with self-reflective rationales.‚Äù In Proceedings of the
2024 Conference on Empirical Methods in Natural Language Processing, pp. 5985‚Äì5998 (2024).</p>
<p>[3] Bo, Yuanchao Emily, et al. ‚ÄúAn IRT forecasting model: Linking proper scoring rules to item response theory.‚Äù Judgment and Decision Making 12.2: 90-103 (2017).</p>
<p>[4] Huang, Tzu-Kuo, et al. ‚ÄúGeneralized Bradley-Terry Models and Multi-Class Probability Estimates.‚Äù Journal of Machine Learning Research 7.1 (2006).</p>
</section>
</section>
</section>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#tl-dr-for-readers-in-a-hurry'" class="reference internal" href="#tl-dr-for-readers-in-a-hurry">TL;DR (for readers in a hurry)</a></li>
<li><a :data-current="activeSection === '#scoring-rules-grounded-metric-for-probabilistic-predictions'" class="reference internal" href="#scoring-rules-grounded-metric-for-probabilistic-predictions">Scoring Rules: grounded metric for probabilistic predictions</a></li>
<li><a :data-current="activeSection === '#averaged-return-what-practitioners-might-care-about'" class="reference internal" href="#averaged-return-what-practitioners-might-care-about">Averaged Return: what practitioners might care about</a><ul>
<li><a :data-current="activeSection === '#absolute-versus-relative-metrics'" class="reference internal" href="#absolute-versus-relative-metrics">üí≠ Absolute versus relative metrics</a></li>
<li><a :data-current="activeSection === '#example-when-would-absolute-and-relative-metrics-differ'" class="reference internal" href="#example-when-would-absolute-and-relative-metrics-differ">ü§î Example: When Would Absolute and Relative Metrics Differ?</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#irt-bradley-terry-lens-of-statistical-modeling'" class="reference internal" href="#irt-bradley-terry-lens-of-statistical-modeling">IRT &amp; Bradley-Terry: lens of statistical modeling</a><ul>
<li><a :data-current="activeSection === '#item-response-theory-irt'" class="reference internal" href="#item-response-theory-irt">Item Response Theory (IRT)</a></li>
<li><a :data-current="activeSection === '#generalized-bradleyterry-bt-model'" class="reference internal" href="#generalized-bradleyterry-bt-model">Generalized Bradley‚ÄìTerry (BT) Model</a></li>
<li><a :data-current="activeSection === '#references'" class="reference internal" href="#references">References:</a></li>
</ul>
</li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">¬© 2025, Prophet Arena Team¬†Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=20e0ead2"></script>
<script src="../_static/doctools.js?v=9bcbadda"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=073f68d9"></script>
<script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>