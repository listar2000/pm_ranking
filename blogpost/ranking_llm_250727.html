<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" data-content_root="../" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" media="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>How We Score &amp; Rank LLMs in Prediction Markets | PM-RANK 0.2.9 documentation</title>
<meta content="How We Score &amp; Rank LLMs in Prediction Markets | PM-RANK 0.2.9 documentation" property="og:title"/>
<meta content="How We Score &amp; Rank LLMs in Prediction Markets | PM-RANK 0.2.9 documentation" name="twitter:title"/>
<link href="../_static/pygments.css?v=e72c8e07" rel="stylesheet" type="text/css"/>
<link href="../_static/theme.css?v=42baaae4" rel="stylesheet" type="text/css"/>
<link href="../_static/graphviz.css?v=4ae1632d" rel="stylesheet" type="text/css"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../autoapi/src/pm_rank/model/utils/index.html" rel="prev" title="src.pm_rank.model.utils"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false, showScrollTop: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">PM-RANK 0.2.9 documentation</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<a href="https://github.com/listar2000/pm_ranking" rel="noopener nofollow" title="Visit GitHub">
<div class="inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md disabled:opacity-50 disabled:pointer-events-none hover:bg-accent hover:text-accent-foreground h-9 w-9">
<svg style="height: 1.75em; width: 1.75em; vertical-align: -0.125em;" viewbox="0 0 496 512">
<path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70.7 1.4-85.9-35.4 0 0-11.4-29.7-27.8-37.4 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" fill="currentColor"></path>
</svg>
</div>
</a>
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" aria-label="Color theme switcher" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../index.html"><span class="font-bold text-clip whitespace-nowrap">PM-RANK 0.2.9 documentation</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Links:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../colab_demo.html">Colab Demo</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../autoapi/src/pm_rank/index.html">src.pm_rank<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../autoapi/src/pm_rank/data/index.html">src.pm_rank.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/src/pm_rank/model/index.html">src.pm_rank.model</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Blogposts:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">How We Score &amp; Rank LLMs in Prediction Markets</a></li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../index.html">
<span class="hidden md:inline">PM-RANK 0.2.9 documentation</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div>
<span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">
    How We Score &amp; Rank LLMs in Prediction Markets
  </span>
</nav>
<div id="content" role="main">
<section id="how-we-score-rank-llms-in-prediction-markets">
<h1>How We Score &amp; Rank LLMs in Prediction Markets<a class="headerlink" href="#how-we-score-rank-llms-in-prediction-markets" title="Link to this heading"><span>¶</span></a></h1>
<blockquote>
<div><p><strong>Author:</strong> Sida Li, Prophet Arena Team</p>
<p><strong>Date:</strong> July 26, 2025</p>
<p><strong>Estimated Reading Time:</strong> 9 minutes</p>
</div></blockquote>
<hr class="docutils"/>
<p>Creating benchmarks and arenas to evaluate large language models (LLMs) is often a labor-intensive and meticulous process. However, when it comes to the metrics used for evaluation, the guiding principle is usually to find a straightforward and intuitive scoring methods for a given task. For example, in problems involving pairwise comparisons (“Which LLM answers better?”), the Elo rating system offers a clean and elegant solution. Likewise, for benchmarks focused on verifiable, objective answers, the evaluation can be as simple as averaging binary correctness across all problems to yield an accuracy metric.</p>
<p>However, the question of <strong>how to score and rank LLMs based on their probabilistic predictions</strong> introduces more complexity and nuance. Choosing the right metrics becomes a non-trivial yet intriguing challenge. One distinctive strength of our platform, <code class="docutils literal notranslate"><span class="pre">ProphetArena</span></code>, lies precisely in our comprehensive scoring and ranking module. This module implements diverse, principled metrics inspired by statistical modeling, utility theory, and psychometrics.</p>
<p>In this post, we’ll guide you through the reasoning behind our metric choices and describe how these metrics help us robustly evaluate LLM performance in prediction-market scenarios.</p>
<section id="tl-dr-for-readers-in-a-hurry">
<h2>TL;DR (for readers in a hurry)<a class="headerlink" href="#tl-dr-for-readers-in-a-hurry" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#tl-dr-for-readers-in-a-hurry'"><span>¶</span></a></h2>
<ul>
<li><p>Our default scoring metric in <code class="docutils literal notranslate"><span class="pre">ProphetArena</span></code> is the <strong>Brier score</strong>—a well-established <a class="reference external" href="https://en.wikipedia.org/wiki/Scoring_rule">proper scoring rule</a>. The Brier score captures the core question:</p>
<blockquote>
<div><p><em>“How well does the predicted probability distribution match reality (the observed outcome)?”</em></p>
</div></blockquote>
<p>It naturally generalizes beyond binary outcomes, assessing both accuracy and calibration.</p>
</li>
<li><p>We’ve innovatively introduced a class of <strong>averaged return metrics</strong> as complementary indicators. Intuitively, these metrics simulate the long-term returns of someone consistently betting based purely on the LLM’s probability estimates, using the same budget for each event.</p></li>
<li><p>We incorporate additional metrics such as an <strong>IRT (Item Response Theory) score</strong>, which jointly models each LLM’s predictive ability alongside event-specific difficulty and discrimination parameters, and a <strong>generalized Bradley–Terry model</strong>, a rating system akin to Elo ratings, providing intuitive comparative scores.</p></li>
<li><p>All these metrics are efficiently implemented and packaged into our standalone Python package <a class="reference external" href="https://pypi.org/project/pm-rank/"><code class="docutils literal notranslate"><span class="pre">pm_rank</span></code></a>, fully documented and open-sourced to facilitate better evaluation of LLMs in general prediction-market environments.</p></li>
</ul>

<p align="center">
<img alt="pm_rank package" src="../_static/rank_overview.png" width="600"/>
</p>
</section>
<section id="scoring-rules-grounded-metric-for-probabilistic-predictions">
<h2>Scoring Rules: grounded metric for probabilistic predictions<a class="headerlink" href="#scoring-rules-grounded-metric-for-probabilistic-predictions" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#scoring-rules-grounded-metric-for-probabilistic-predictions'"><span>¶</span></a></h2>
<p><strong>We begin with some setup:</strong> we want to score the LLM’s probabilistic predictions for multiple events <span class="math notranslate nohighlight">\(E_1,...,E_N\)</span>. In each event <span class="math notranslate nohighlight">\(i\)</span>, there are <span class="math notranslate nohighlight">\(n_i\)</span> mutually exclusive potential outcomes (e.g. <span class="math notranslate nohighlight">\(n_i = 30\)</span> for the event <em>“NBA champion in 2026”</em>). The LLM prediction is then represented as a probability vector <span class="math notranslate nohighlight">\((p_{i1}, p_{i2}, \dots, p_{in_i})\)</span>, summing to 1. Once the event outcome is realized—say, outcome <span class="math notranslate nohighlight">\(j\)</span>—we calculate the prediction accuracy using scoring rules, specifically for the Brier score:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
BS_i \equiv \text{Brier Score for } E_i = \frac{1}{n_i} \sum_{k=1}^{n_i}(p_{ik} - o_{ik})^2
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(o_{ik}\)</span> is 1 if outcome <span class="math notranslate nohighlight">\(k\)</span> occurred, and 0 otherwise. This metric provides a clean numeric score between 0 and 1, with lower scores indicating better accuracy and calibration. The final (averaged) Brier score is then calculated across all events:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
BS = \frac{1}{N} \sum_{i=1}^{N} BS_i
\end{equation*}\]</div>
<p>and used as the score to rank the LLMs (the smaller the better).</p>
<p>Unlike simple accuracy measures, scoring rules like the Brier score provide richer information, particularly useful when dealing with multiple outcomes (<span class="math notranslate nohighlight">\(n_i &gt; 2\)</span>). For example, traditional accuracy metrics become ambiguous when no single outcome has an assigned probability exceeding 0.5—should we pick the highest-probability option, or refuse to make a deterministic guess? Scoring rules elegantly bypass this ambiguity by directly measuring how closely predicted probabilities align with the observed outcomes.</p>
<p>Furthermore, proper scoring rules inherently reward models that are both accurate and well-calibrated. In simple terms, a well-calibrated predictor enjoys the property that outcomes predicted with 70% probability truly occur around 70% of the time (here 70% is just a convenient choice), ensuring reliability in practical applications.</p>
<p>It’s worth noting that popular real-world forecasting platforms, such as <a class="reference external" href="https://www.gjopen.com/">Good Judgment Open</a>, also widely adopt variations of the Brier score, showing its long-established practicality in prediction markets. Several recent academic works have also explored the application of scoring rules in LLMs, such as in designing RL reward functions [1] and confidence elicitation [2].</p>
<p>While the Brier score serves as our default scoring method due to its interpretability and robustness, we also make other proper scoring rules, such as the logarithmic (log) and spherical scores, availabe in the <code class="docutils literal notranslate"><span class="pre">pm_rank</span></code> package. The intuitive interpretation of the Brier score makes it our primary evaluation metric.</p>
</section>
<section id="averaged-return-what-practitioners-might-care-about">
<h2>Averaged Return: what practitioners might care about<a class="headerlink" href="#averaged-return-what-practitioners-might-care-about" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#averaged-return-what-practitioners-might-care-about'"><span>¶</span></a></h2>
<p>In real-world prediction markets, practitioners care deeply about <strong>actionable insights</strong>—specifically, how much money one could earn by faithfully following an LLM’s probabilistic predictions. However, LLMs only provide probabilistic estimates rather than direct recommendations for betting actions. Turning these estimates into concrete actions typically involves comparing the LLM’s belief (probability) against market-implied probabilities.</p>
<p>To address this, we’ve introduced a novel approach rooted in <strong>constant-relative-risk-aversion (CRRA) utility theory</strong>. Specifically, we assume a hypothetical scenario where a human fully trusts the LLM’s probabilities as their true beliefs and makes decisions guided solely by their personal risk aversion, captured by the CRRA utility function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
U_\gamma(w)=
\begin{cases}
\dfrac{w^{1-\gamma}}{\,1-\gamma\,}, &amp; 0\le\gamma&lt;1, \\
\log w, &amp; \gamma=1
\end{cases}
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma \in [0, 1]\)</span> is a risk-aversion hyperparameter, and <span class="math notranslate nohighlight">\(w\)</span> is the amount of money earned after making the bet. A <span class="math notranslate nohighlight">\(\gamma = 0\)</span> characterizes a risk-neutral individual, while <span class="math notranslate nohighlight">\(\gamma = 1\)</span> represents a logarithmic risk-averse profile. Intermediate values of <span class="math notranslate nohighlight">\(\gamma\)</span> represent varying degrees of risk aversion.</p>
<p align="center">
<img alt="CRRA Utility Function" src="../_static/crra_utility_plot.png" title="CRRA Utility Function" width="700"/>
</p>
<p>Other than the utility function, two other factors would influence the <strong>optimal betting strategy</strong>:</p>
<ol class="arabic simple">
<li><p><strong>How much money (total budget) to bet:</strong> for simplicity, we assume in our hypothetical scenarior that the bettor has a fixed budget of <strong>one dollar</strong> for each event, so the total budget is <span class="math notranslate nohighlight">\(N\)</span>. In other words, for the <span class="math notranslate nohighlight">\(i\)</span>-th event, any <strong>action/strategy</strong> can be represented as a vector <span class="math notranslate nohighlight">\(a_i = (a_{i1}, a_{i2}, \dots, a_{in_i})\)</span> that sums to 1, where <span class="math notranslate nohighlight">\(a_{ik}\)</span> is the amount bet on outcome <span class="math notranslate nohighlight">\(k\)</span> of event <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p><strong>The market odds/implied probabilities:</strong> these are the probabilities derived from the (human) market prices of the outcomes, which we denote as <span class="math notranslate nohighlight">\(q_{ik}\)</span> for outcome <span class="math notranslate nohighlight">\(k\)</span> of event <span class="math notranslate nohighlight">\(i\)</span>. In simple terms, <span class="math notranslate nohighlight">\(q_{ik}\)</span> is the market-consensus price of an “all-or-nothing” contract, which pays one dollar if outcome <span class="math notranslate nohighlight">\(k\)</span> occurs and zero otherwise. In practice, we retrieve this information from human prediction markets, such as <a class="reference external" href="https://kalshi.com/">Kalshi</a>.</p></li>
</ol>
<p>Once these factors are determined, we can determine the optimal strategy <span class="math notranslate nohighlight">\(a_i^*\)</span> for event <span class="math notranslate nohighlight">\(E_i\)</span> by solving an optimization problem. The <em>optimality</em> is defined in terms of maximizing the expected utility of the bettor, given their risk aversion <span class="math notranslate nohighlight">\(\gamma\)</span> and using LLM’s predicted probabilities <span class="math notranslate nohighlight">\(p_{ik}\)</span> as the true beliefs. While the detailed derivation is beyond the scope of this post, the solution can be expressed in closed and interpretable forms depending on the risk aversion <span class="math notranslate nohighlight">\(\gamma\)</span>:</p>
<ul class="simple">
<li><p><strong>Risk-neutral (linear utility)</strong> individuals (<span class="math notranslate nohighlight">\(\gamma=0\)</span>) bet entirely on the option with the greatest discrepancy (<span class="math notranslate nohighlight">\(k^* := \max_k \frac{p_{ik}}{q_{ik}}\)</span>, sometimes denoted as <strong>edge</strong>) between LLM probabilities and market odds.</p></li>
<li><p><strong>Logarithmic utility (<span class="math notranslate nohighlight">\(\gamma=1\)</span>)</strong> bettors allocate their budget proportionally according to the LLM’s probabilities, i.e. <span class="math notranslate nohighlight">\(a_{ik}^* \propto p_{ik}\)</span>.</p></li>
<li><p><strong>Intermediate risk aversions (<span class="math notranslate nohighlight">\(0 &lt; \gamma &lt; 1\)</span>)</strong> smoothly interpolate between these two extremes, providing flexible yet clearly interpretable betting strategies.</p></li>
</ul>
<p>Our averaged return metric then measures the long-term rate of return by following the optimal betting strategy <span class="math notranslate nohighlight">\(a_i^*\)</span> across all events. Specifically, we define the <strong>averaged return score (AVER)</strong> as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
AVER := \frac{\sum_{i=1}^{N} \text{payoff from } i\text{-th } \text{event under } a_i^*}{N}.
\end{equation*}\]</div>
<p>where the payoff is simply <span class="math notranslate nohighlight">\(a_{ik}^*\)</span> whenever outcome <span class="math notranslate nohighlight">\(k\)</span> occurs. We need to specify the hyperparameter <span class="math notranslate nohighlight">\(\gamma\)</span> to compute the AVER. By default, we follow the risk-neutral case (<span class="math notranslate nohighlight">\(\gamma=0\)</span>), but our platform also allows users to vary this factor (perhaps based on their own risk preferences). Below we show three moving AVER metrics over time (as more and more prediction events are closed) for four LLMs and <span class="math notranslate nohighlight">\(\gamma = 0, 0.5, 1\)</span>:</p>
<p align="center">
<img alt="Averaged Return Score" src="../_static/prophet_arena_risk_curves_0717.png" title="Averaged return curves for LLMs, generated with `pm_rank`." width="800"/>
<p>Creating such plots is straightforward and efficient using the built-in functions in the <code class="docutils literal notranslate"><span class="pre">pm_rank</span></code> package.</p>
</p>
<section id="absolute-versus-relative-metrics">
<h3>💭 Absolute versus relative metrics<a class="headerlink" href="#absolute-versus-relative-metrics" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#absolute-versus-relative-metrics'"><span>¶</span></a></h3>
<p>It is now the right time to reflect and compare the two important metrics introduced so far. Despite the obvious differences in their mathematical formulations, a more high-level distinction to keep in mind is that: the Brier score is an <strong>absolute metric</strong>, while the averaged return score is a <strong>relative metric</strong>. To elaborate:</p>
<ul class="simple">
<li><p>When we calculate the Brier score (or any other proper scoring rule), we measure how the LLM’s probabilistic predictions align with the observed outcomes. A good score means that the LLM can effectively synthesize the provided information and make accurate &amp; well-calibrated predictions through reasoning. The market odds, which can be interpreted as the human-consensus probabilities, <strong>do not enter into the calculation</strong>.</p></li>
<li><p>On the other hand, the averaged return depends on the observed outcome and the strategy <span class="math notranslate nohighlight">\(a_i^*\)</span>, which in turn is determined by <strong>both the LLM’s probabilities and the market odds</strong>. It is thus a <strong>relative metric</strong> in the sense that achieving a good score requires the LLM to perform “relatively better” than most human bettors to create arbitrage opportunities.</p></li>
</ul>
<br/>
<details>
<summary>🤔 Follow-up: when would rankings based on these two metrics differ?</summary>
<p>Imagine the following stylized setup:</p>
<ul class="simple">
<li><p>There are two LLMs, <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, and all events fall under two categories, <code class="docutils literal notranslate"><span class="pre">finance</span></code> and <code class="docutils literal notranslate"><span class="pre">sports</span></code> (50-50 proportion).</p></li>
<li><p>For human market, it is relatively more “predictable” in the <code class="docutils literal notranslate"><span class="pre">sports</span></code> category, while the <code class="docutils literal notranslate"><span class="pre">finance</span></code> events require more information aggregation and are thus harder to predict.</p></li>
<li><p>For LLM <span class="math notranslate nohighlight">\(A\)</span>, it is substantially better at predicting the <code class="docutils literal notranslate"><span class="pre">sports</span></code> events than <span class="math notranslate nohighlight">\(B\)</span>, while it is slightly worse at predicting the <code class="docutils literal notranslate"><span class="pre">finance</span></code> events.</p></li>
<li><p>Now, LLM <span class="math notranslate nohighlight">\(A\)</span> will have better Brier score than <span class="math notranslate nohighlight">\(B\)</span> because overall it has better predictive capabilities in the <strong>absolute sense</strong> (ignoring market odds).</p></li>
<li><p>However, if we consider the averaged return score, we will find that LLM <span class="math notranslate nohighlight">\(B\)</span> will have a better score than <span class="math notranslate nohighlight">\(A\)</span> because it is able to make more money in the <code class="docutils literal notranslate"><span class="pre">finance</span></code> events where humans are more inferior at. Despite its strong predictive capabilities in the <code class="docutils literal notranslate"><span class="pre">sports</span></code> events, LLM <span class="math notranslate nohighlight">\(A\)</span> is not able to create arbitrage opportunities there since humans are also very good at these problems.</p></li>
</ul>
</details>
</section>
</section>
<section id="irt-bradley-terry-lens-of-statistical-modeling">
<h2>IRT &amp; Bradley-Terry: lens of statistical modeling<a class="headerlink" href="#irt-bradley-terry-lens-of-statistical-modeling" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#irt-bradley-terry-lens-of-statistical-modeling'"><span>¶</span></a></h2>
<p>In addition to the previously mentioned metrics, we also incorporate statistically-grounded methods such as <strong>Item Response Theory (IRT)</strong> and the <strong>Bradley–Terry (BT) model</strong> to gain deeper insights into LLM performance. Unlike simpler metrics, these methods rely on fitting statistical models to data—thus they tend to require larger datasets and careful model fitting procedures.</p>
<section id="item-response-theory-irt">
<h3>Item Response Theory (IRT)<a class="headerlink" href="#item-response-theory-irt" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#item-response-theory-irt'"><span>¶</span></a></h3>
<p>IRT addresses a critical limitation in simpler scoring methods: equal weighting of all prediction events. Using a slight variant [3] of the <a class="reference external" href="https://assess.com/what-is-the-two-parameter-irt-2pl-model/">two-parameter logistic (2-PL) IRT model</a>, we jointly estimate each LLM’s capability parameter alongside the <strong>difficulty and discrimination parameters</strong> for each prediction event. Higher discrimination parameters indicate events that more effectively distinguish strong from weak predictors, thus implicitly assigning more weight to these informative events.</p>
<p>This approach is highly versatile. The final scoring can be either (i) the directly fitted capability parameters of the LLMs in the IRT model or (ii) weighted scoring rules (e.g. Brier score) using event-level discrimination parameters. While traditionally the 2-PL IRT model assumes binary outcomes (correct/incorrect), our implementation also accommodates continuous responses, such as directly using the Brier score as the data.</p>
<p>Initial empirical results suggest that: even though IRT model fitting requires scaling up both the number of prediction events and the number of LLMs, it provides a robust and principled evaluation framework (in the sense that the two implementations (i) and (ii) above achieve high correlation). Once we obtan sufficient data, it is expected that <strong>we might migrate our default scoring metric from the current (unweighted) Brier score to the IRT-based weighted version</strong>, and we will likely publish a separate follow-up post detailing our practice.</p>
</section>
<section id="generalized-bradleyterry-bt-model">
<h3>Generalized Bradley–Terry (BT) Model<a class="headerlink" href="#generalized-bradleyterry-bt-model" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#generalized-bradleyterry-bt-model'"><span>¶</span></a></h3>
<p>The generalized BT model [4] extends traditional pairwise-comparison methods—like those used by <a class="reference external" href="https://lmarena.ai/">LMArena</a>—to our prediction-market setting. Here, each event outcome is viewed as a contest between two “pseudo-teams”: a winning team <span class="math notranslate nohighlight">\(w_i\)</span> (corresponding to the realized outcome) and a losing team <span class="math notranslate nohighlight">\(l_i\)</span>. Each participating LLM contributes fractions of its capability proportional to its predicted probabilities, allocating <span class="math notranslate nohighlight">\(p_{ik}\)</span> to the winning team and <span class="math notranslate nohighlight">\(1 - p_{ik}\)</span> to the losing team.</p>
<p>We model the winning probability for <span class="math notranslate nohighlight">\(E_i\)</span> using the BT formulation:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\frac{e^{\theta_{w_i}}}{e^{\theta_{w_i}} + e^{\theta_{l_i}}}
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_{w_i}\)</span> and <span class="math notranslate nohighlight">\(\theta_{l_i}\)</span> are the summed <em>“fractional”</em> capabilities of the winning and losing teams, respectively. Although this generalization introduces an artificial element by translating a non-pairwise prediction scenario into a pairwise framework, it provides a familiar comparative rating approach. Admittedly, we have not thoroughly explored the statistical properties and convergence guarantees of this generalized BT model, yet it remains a valuable addition to our suite of evaluation tools.</p>
</section>
<hr class="docutils"/>
<section id="references">
<h3>References:<a class="headerlink" href="#references" title="Link to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#references'"><span>¶</span></a></h3>
<p>[1] Damani, Mehul, et al. “Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty.” arXiv preprint arXiv:2507.16806 (2025).</p>
<p>[2] Xu, Tianyang, et al. “Sayself: Teaching llms to express confidence with self-reflective rationales.” In Proceedings of the
2024 Conference on Empirical Methods in Natural Language Processing, pp. 5985–5998 (2024).</p>
<p>[3] Bo, Yuanchao Emily, et al. “An IRT forecasting model: Linking proper scoring rules to item response theory.” Judgment and Decision Making 12.2: 90-103 (2017).</p>
<p>[4] Huang, Tzu-Kuo, et al. “Generalized Bradley-Terry Models and Multi-Class Probability Estimates.” Journal of Machine Learning Research 7.1 (2006).</p>
</section>
</section>
</section>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#tl-dr-for-readers-in-a-hurry'" class="reference internal" href="#tl-dr-for-readers-in-a-hurry">TL;DR (for readers in a hurry)</a></li>
<li><a :data-current="activeSection === '#scoring-rules-grounded-metric-for-probabilistic-predictions'" class="reference internal" href="#scoring-rules-grounded-metric-for-probabilistic-predictions">Scoring Rules: grounded metric for probabilistic predictions</a></li>
<li><a :data-current="activeSection === '#averaged-return-what-practitioners-might-care-about'" class="reference internal" href="#averaged-return-what-practitioners-might-care-about">Averaged Return: what practitioners might care about</a><ul>
<li><a :data-current="activeSection === '#absolute-versus-relative-metrics'" class="reference internal" href="#absolute-versus-relative-metrics">💭 Absolute versus relative metrics</a></li>
</ul>
</li>
<li><a :data-current="activeSection === '#irt-bradley-terry-lens-of-statistical-modeling'" class="reference internal" href="#irt-bradley-terry-lens-of-statistical-modeling">IRT &amp; Bradley-Terry: lens of statistical modeling</a><ul>
<li><a :data-current="activeSection === '#item-response-theory-irt'" class="reference internal" href="#item-response-theory-irt">Item Response Theory (IRT)</a></li>
<li><a :data-current="activeSection === '#generalized-bradleyterry-bt-model'" class="reference internal" href="#generalized-bradleyterry-bt-model">Generalized Bradley–Terry (BT) Model</a></li>
<li><a :data-current="activeSection === '#references'" class="reference internal" href="#references">References:</a></li>
</ul>
</li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2025, Prophet Arena Team Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
</div>
<script src="../_static/documentation_options.js?v=14672bda"></script>
<script src="../_static/doctools.js?v=9bcbadda"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script defer="defer" src="../_static/theme.js?v=073f68d9"></script>
<script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>